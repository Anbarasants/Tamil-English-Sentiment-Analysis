{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446109,"status":"ok","timestamp":1736443019622,"user":{"displayName":"ANBARASAN T 22CSR017","userId":"16535093453500537596"},"user_tz":-330},"id":"0q1ErRicCfz8","outputId":"4937805f-9904-44af-ac37-175f529487ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label\n","Positive          0.583028\n","unknown_state     0.165928\n","Negative          0.133378\n","Mixed_feelings    0.117666\n","Name: proportion, dtype: float64\n","Label Mapping: {0: 'Mixed_feelings', 1: 'Negative', 2: 'Positive', 3: 'unknown_state'}\n","Epoch 1/5: Train Loss: 1.0549, Train Acc: 0.5916, Val Loss: 1.0578, Val Acc: 0.5667\n","Epoch 2/5: Train Loss: 0.8716, Train Acc: 0.6676, Val Loss: 1.0655, Val Acc: 0.5986\n","Epoch 3/5: Train Loss: 0.6130, Train Acc: 0.7805, Val Loss: 1.2015, Val Acc: 0.5969\n","Epoch 4/5: Train Loss: 0.3807, Train Acc: 0.8727, Val Loss: 1.3900, Val Acc: 0.5740\n","Epoch 5/5: Train Loss: 0.2776, Train Acc: 0.9082, Val Loss: 1.5849, Val Acc: 0.5841\n","Predictions saved to /content/drive/MyDrive/codalab/tam_CNN_prediction.csv\n"]}],"source":["import pandas as pd\n","import re\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from collections import Counter\n","from itertools import chain\n","\n","# Load the datasets\n","train_file_path = '/content/Tam-SA-train.csv'\n","test_file_path = '/content/Tam-SA-test-without-labels.csv'\n","\n","train_data = pd.read_csv(train_file_path)\n","test_data = pd.read_csv(test_file_path)\n","\n","# Analyze class distribution\n","print(train_data['Label'].value_counts(normalize=True))\n","\n","# Preprocessing function for text data\n","def preprocess_text(text):\n","    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n","    text = re.sub(r\"\\s+\", \" \", text).strip()    # Remove extra spaces\n","    return text.lower()\n","\n","# Apply preprocessing\n","train_data['Cleaned_Text'] = train_data['Text'].apply(preprocess_text)\n","test_data['Cleaned_Text'] = test_data['Text'].apply(preprocess_text)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","train_data['Encoded_Label'] = label_encoder.fit_transform(train_data['Label'])\n","\n","# Define label mapping for reference\n","label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n","print(\"Label Mapping:\", label_mapping)\n","\n","# Split training data into train and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(\n","    train_data['Cleaned_Text'], train_data['Encoded_Label'],\n","    test_size=0.2, random_state=42, stratify=train_data['Encoded_Label']\n",")\n","\n","# Build vocabulary\n","def build_vocab(sentences, vocab_size=20000):\n","    words = chain(*[sentence.split() for sentence in sentences])\n","    most_common = Counter(words).most_common(vocab_size - 2)\n","    word_to_idx = {word: idx + 2 for idx, (word, _) in enumerate(most_common)}\n","    word_to_idx[\"<PAD>\"] = 0\n","    word_to_idx[\"<UNK>\"] = 1\n","    return word_to_idx\n","\n","vocab = build_vocab(X_train, vocab_size=20000)\n","vocab_size = len(vocab)\n","\n","# Custom dataset class\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels, vocab, max_length=100):\n","        self.texts = texts.tolist()\n","        self.labels = labels.tolist()\n","        self.vocab = vocab\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def encode_text(self, text):\n","        tokens = text.split()\n","        encoded = [self.vocab.get(token, self.vocab[\"<UNK>\"]) for token in tokens]\n","        padded = encoded[:self.max_length] + [self.vocab[\"<PAD>\"]] * max(0, self.max_length - len(encoded))\n","        return padded\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        return torch.tensor(self.encode_text(text), dtype=torch.long), torch.tensor(label, dtype=torch.long)\n","\n","# Create datasets and data loaders\n","train_dataset = TextDataset(X_train, y_train, vocab, max_length=100)\n","val_dataset = TextDataset(X_val, y_val, vocab, max_length=100)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32)\n","\n","# Define CNN model\n","class CNNModel(nn.Module):\n","    def __init__(self, vocab_size, embed_size, num_classes, kernel_sizes, num_channels):\n","        super(CNNModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.convs = nn.ModuleList([\n","            nn.Conv1d(in_channels=embed_size, out_channels=num_channels, kernel_size=ks)\n","            for ks in kernel_sizes\n","        ])\n","        self.fc = nn.Linear(num_channels * len(kernel_sizes), num_classes)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x).permute(0, 2, 1)\n","        conv_outs = [torch.relu(conv(embedded)).max(dim=2)[0] for conv in self.convs]\n","        out = torch.cat(conv_outs, dim=1)\n","        return self.fc(out)\n","\n","# Initialize model, loss, and optimizer\n","embed_size = 128\n","num_classes = len(label_mapping)\n","kernel_sizes = [3, 4, 5]\n","num_channels = 100\n","\n","model = CNNModel(vocab_size, embed_size, num_classes, kernel_sizes, num_channels)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=5):\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss, train_correct = 0, 0\n","        for texts, labels in train_loader:\n","            texts, labels = texts.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(texts)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","            train_correct += (outputs.argmax(1) == labels).sum().item()\n","\n","        val_loss, val_correct = 0, 0\n","        model.eval()\n","        with torch.no_grad():\n","            for texts, labels in val_loader:\n","                texts, labels = texts.to(device), labels.to(device)\n","                outputs = model(texts)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","                val_correct += (outputs.argmax(1) == labels).sum().item()\n","\n","        print(f\"Epoch {epoch + 1}/{epochs}: \"\n","              f\"Train Loss: {train_loss / len(train_loader):.4f}, \"\n","              f\"Train Acc: {train_correct / len(train_loader.dataset):.4f}, \"\n","              f\"Val Loss: {val_loss / len(val_loader):.4f}, \"\n","              f\"Val Acc: {val_correct / len(val_loader.dataset):.4f}\")\n","\n","train_model(model, criterion, optimizer, train_loader, val_loader, epochs=5)\n","\n","# Predict function for the test dataset\n","def predict_test(model, test_texts, vocab, max_length=100):\n","    model.eval()\n","    encoded_texts = [\n","        torch.tensor([vocab.get(token, vocab[\"<UNK>\"]) for token in text.split()][:max_length] +\n","                     [vocab[\"<PAD>\"]] * max(0, max_length - len(text.split())),\n","                     dtype=torch.long)\n","        for text in test_texts\n","    ]\n","    test_dataset = torch.stack(encoded_texts)\n","    test_loader = DataLoader(test_dataset, batch_size=32)\n","\n","    predictions = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            batch = batch.to(device)\n","            outputs = model(batch)\n","            predictions.extend(outputs.argmax(1).cpu().numpy())\n","    return predictions\n","\n","# Get predictions for the test file\n","test_texts = test_data['Cleaned_Text']\n","predicted_labels = predict_test(model, test_texts, vocab, max_length=100)\n","\n","# Map predicted numeric labels back to original labels\n","predicted_labels_decoded = label_encoder.inverse_transform(predicted_labels)\n","\n","# Save predictions to CSV\n","output_df = pd.DataFrame({\n","    \"Text\": test_data['Text'],\n","    \"Predicted_Label\": predicted_labels_decoded\n","})\n","output_csv_path = '/content/drive/MyDrive/codalab/tam_CNN_prediction.csv'\n","output_df.to_csv(output_csv_path, index=False)\n","print(f\"Predictions saved to {output_csv_path}\")\n"]},{"cell_type":"code","source":["# Define and load model (if needed)\n","model = CNNModel(vocab_size, embed_size, num_classes, kernel_sizes, num_channels)\n","model.load_state_dict(torch.load(\"model_checkpoint.pth\"))  # Load checkpoint if saved\n","model.to(device)\n","model.eval()\n"],"metadata":{"id":"KLnqO-r9C-3n","executionInfo":{"status":"error","timestamp":1738170696278,"user_tz":-330,"elapsed":400,"user":{"displayName":"ANBARASAN T 22CSR017","userId":"16535093453500537596"}},"outputId":"c621eeea-9152-4d17-9e05-75746c6f83a4","colab":{"base_uri":"https://localhost:8080/","height":211}},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'CNNModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-a648c000cb02>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define and load model (if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_checkpoint.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load checkpoint if saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CNNModel' is not defined"]}]},{"cell_type":"code","source":["import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","# Get model predictions on the validation set\n","model.eval()\n","all_preds, all_labels = [], []\n","\n","with torch.no_grad():\n","    for texts, labels in val_loader:\n","        texts, labels = texts.to(device), labels.to(device)\n","        outputs = model(texts)\n","        preds = outputs.argmax(1).cpu().numpy()\n","        all_preds.extend(preds)\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(all_labels, all_preds)\n","labels = [label_mapping[i] for i in range(len(label_mapping))]  # Get class labels\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"mFW9_xXXAtWo","executionInfo":{"status":"error","timestamp":1738170270850,"user_tz":-330,"elapsed":394,"user":{"displayName":"ANBARASAN T 22CSR017","userId":"16535093453500537596"}},"outputId":"78500266-1221-4fc1-92a5-0334e5d80fc5"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c0898ea0df6a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get model predictions on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":677,"referenced_widgets":["1ff37026e9ec473aa4c939ef0da7a075","e0cbb2f4ce3c475d9b05a808173a9b1c","3babb5f85f914018bf3734cddd16b1c4","55fb14056d1d4bdb8d4677f5e19dc770","2825ce7532c24996b7666861210f15a2","6a695637b0134716ac1fbc3fb1ea53d9","e36fd5315459498fb3016ab4208718bc","78dcd6603a0b455b9ced95011fd21920","9d0def64b25249238c1016622a3ab48a","260a681f1001433a82f2f716ac11f549","f6cf0e55619b419b940e447764f6e31b","617ddd6ba82a401ca6ff54df9583ed86","abc0c2300f2649de84c120e86532f394","3ded4f7155304204851673163352bd27","8b1a9737521a4a7ba9162a953e6ecf10","4ad07e7bd31f4396b677c763d9f2d10b","8a1caf2f3ea84c0480d324fb5a4af200","715c887f2fc749d8b202e882668d5650","546c6b9c50b54aa2aa579163a1d4a35f","ad5211b78b2c4adb8aa5b373fd14cce8","896fd88532104163a369a4bcd605aa2b","f944e7e465ec4b389741cd3396fe7d05","8e6a815560214aafb203cbca4f2a9884","2e2eed49e43b43869e1932b1fa3c230c","6db5337347ab462daee5753dadbcd006","d3c4e0ecdf7b4da98372c22cf5166541","81b4b2879b7546feba01edbfbf2c0fff","446128655c0047d0804c21bc65deaae4","30558cb5562b457184d1becb309a3abd","fc677d10b5474f939a1fe50be47d2a00","a79bc0889b884f25b91c6e3a621b9214","771e7f532e984b83a05aa53c82584dc6","b99ece4666294bcd88ea7ed876555d36","e0d3b3eac2614142ae9b868bf92db50d","51d54350a22e49b5b0da16cdd49a78ab","35eef1e75a59414b909e90a050e9ac3b","527cda7172d943f992edc72796734825","40e540f45f0d415fbb0547dfec04ab5d","2d889f4d65aa4184a4a0795c31d219cf","19c4df29465e4a4c956eab4e15978a46","62451753d71545c78625853cf9c2720f","16d458d56f0b41adba0ca644a2613dda","bc3f4cdf0bae43cab86c43829fab3d03","f1d8bcbc6a3e4b68b2e4e3ab848dacd8"]},"id":"0ry467puKS7J","outputId":"a2a58ace-f695-4a9b-8caa-48f12151c6d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label Mapping: {0: 'Mixed_feelings', 1: 'Negative', 2: 'Positive', 3: 'unknown_state'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ff37026e9ec473aa4c939ef0da7a075","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"617ddd6ba82a401ca6ff54df9583ed86","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e6a815560214aafb203cbca4f2a9884","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0d3b3eac2614142ae9b868bf92db50d","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250109_174339-b6exmvxj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/anbarasant-22cse-institution/huggingface/runs/b6exmvxj' target=\"_blank\">./xlnet_results</a></strong> to <a href='https://wandb.ai/anbarasant-22cse-institution/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/anbarasant-22cse-institution/huggingface' target=\"_blank\">https://wandb.ai/anbarasant-22cse-institution/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/anbarasant-22cse-institution/huggingface/runs/b6exmvxj' target=\"_blank\">https://wandb.ai/anbarasant-22cse-institution/huggingface/runs/b6exmvxj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1017' max='6226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1017/6226 1:58:55 < 10:10:20, 0.14 it/s, Epoch 0.33/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import re\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from transformers import (\n","    XLNetTokenizer,\n","    XLNetForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n",")\n","\n","# Load the datasets\n","train_file_path = '/content/Tam-SA-train.csv'\n","test_file_path = '/content/Tam-SA-test-without-labels.csv'\n","\n","train_data = pd.read_csv(train_file_path)\n","test_data = pd.read_csv(test_file_path)\n","\n","# Preprocess the text data\n","def preprocess_text(text):\n","    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n","    text = re.sub(r\"\\s+\", \" \", text).strip()    # Remove extra spaces\n","    return text.lower()\n","\n","train_data['Cleaned_Text'] = train_data['Text'].apply(preprocess_text)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","train_data['Encoded_Label'] = label_encoder.fit_transform(train_data['Label'])\n","\n","# Create label mapping\n","label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n","print(\"Label Mapping:\", label_mapping)\n","\n","# Split the data into train and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(\n","    train_data['Cleaned_Text'], train_data['Encoded_Label'],\n","    test_size=0.2, random_state=42, stratify=train_data['Encoded_Label']\n",")\n","\n","# Define a custom dataset for tokenized text\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        self.texts = texts.tolist()\n","        self.labels = labels.tolist()\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\",\n","        )\n","        return {\n","            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n","            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n","            \"labels\": torch.tensor(label, dtype=torch.long),\n","        }\n","\n","# Initialize tokenizer and datasets\n","tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n","max_length = 64  # Reduced max length for faster training\n","\n","train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)\n","val_dataset = SentimentDataset(X_val, y_val, tokenizer, max_length)\n","\n","# Load XLNet model\n","num_labels = len(label_mapping)\n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)\n","\n","# Freeze lower layers\n","for param in model.transformer.layer[:6]:\n","    param.requires_grad = False\n","\n","# Define training arguments with fewer epochs and mixed precision\n","training_args = TrainingArguments(\n","    output_dir=\"./xlnet_results\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,  # Smaller batch size for speed\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,  # Reduced epochs\n","    weight_decay=0.01,\n","    fp16=True,  # Enable mixed precision\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_total_limit=2,\n",")\n","\n","# Define a compute_metrics function for evaluation\n","from sklearn.metrics import accuracy_score\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n","    accuracy = accuracy_score(labels, predictions)\n","    return {\"accuracy\": accuracy}\n","\n","# Initialize Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Save the trained model and tokenizer\n","model.save_pretrained(\"./xlnet_model\")\n","tokenizer.save_pretrained(\"./xlnet_model\")\n","\n","# Evaluate the model on the validation dataset\n","eval_results = trainer.evaluate()\n","print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTJAzugPKgU4"},"outputs":[],"source":["# Preprocess and tokenize the test data\n","test_data['Cleaned_Text'] = test_data['Text'].apply(preprocess_text)\n","\n","class TestDataset(Dataset):\n","    def __init__(self, texts, tokenizer, max_length):\n","        self.texts = texts.tolist()\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\",\n","        )\n","        return {\n","            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n","            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n","        }\n","\n","# Create test dataset and loader\n","test_dataset = TestDataset(test_data['Cleaned_Text'], tokenizer, max_length)\n","test_loader = DataLoader(test_dataset, batch_size=8)\n","\n","# Make predictions on the test dataset\n","model.eval()\n","predictions = []\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch['input_ids'].to(training_args.device)\n","        attention_mask = batch['attention_mask'].to(training_args.device)\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        preds = torch.argmax(outputs.logits, dim=-1)\n","        predictions.extend(preds.cpu().tolist())\n","\n","# Map predictions to labels\n","test_data['Predicted_Label'] = [label_mapping[pred] for pred in predictions]\n","\n","# Save the predictions to a CSV file\n","output_file_path = '/content/drive/MyDrive/codalab/tam_XLNET_prediction.csv'\n","test_data[['Text', 'Predicted_Label']].to_csv(output_file_path, index=False)\n","print(f\"Predictions saved to {output_file_path}\")\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1dSQAoMpVFiBjBF8InrBYRnVTj56UUaYk","authorship_tag":"ABX9TyNdp6esKBZIsOIu9+P++rLS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"16d458d56f0b41adba0ca644a2613dda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19c4df29465e4a4c956eab4e15978a46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ff37026e9ec473aa4c939ef0da7a075":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0cbb2f4ce3c475d9b05a808173a9b1c","IPY_MODEL_3babb5f85f914018bf3734cddd16b1c4","IPY_MODEL_55fb14056d1d4bdb8d4677f5e19dc770"],"layout":"IPY_MODEL_2825ce7532c24996b7666861210f15a2"}},"260a681f1001433a82f2f716ac11f549":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2825ce7532c24996b7666861210f15a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d889f4d65aa4184a4a0795c31d219cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e2eed49e43b43869e1932b1fa3c230c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_446128655c0047d0804c21bc65deaae4","placeholder":"â€‹","style":"IPY_MODEL_30558cb5562b457184d1becb309a3abd","value":"config.json:â€‡100%"}},"30558cb5562b457184d1becb309a3abd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35eef1e75a59414b909e90a050e9ac3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62451753d71545c78625853cf9c2720f","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16d458d56f0b41adba0ca644a2613dda","value":467042463}},"3babb5f85f914018bf3734cddd16b1c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78dcd6603a0b455b9ced95011fd21920","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d0def64b25249238c1016622a3ab48a","value":798011}},"3ded4f7155304204851673163352bd27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_546c6b9c50b54aa2aa579163a1d4a35f","max":1382015,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad5211b78b2c4adb8aa5b373fd14cce8","value":1382015}},"40e540f45f0d415fbb0547dfec04ab5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"446128655c0047d0804c21bc65deaae4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ad07e7bd31f4396b677c763d9f2d10b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51d54350a22e49b5b0da16cdd49a78ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d889f4d65aa4184a4a0795c31d219cf","placeholder":"â€‹","style":"IPY_MODEL_19c4df29465e4a4c956eab4e15978a46","value":"pytorch_model.bin:â€‡100%"}},"527cda7172d943f992edc72796734825":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc3f4cdf0bae43cab86c43829fab3d03","placeholder":"â€‹","style":"IPY_MODEL_f1d8bcbc6a3e4b68b2e4e3ab848dacd8","value":"â€‡467M/467Mâ€‡[00:06&lt;00:00,â€‡76.0MB/s]"}},"546c6b9c50b54aa2aa579163a1d4a35f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55fb14056d1d4bdb8d4677f5e19dc770":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_260a681f1001433a82f2f716ac11f549","placeholder":"â€‹","style":"IPY_MODEL_f6cf0e55619b419b940e447764f6e31b","value":"â€‡798k/798kâ€‡[00:00&lt;00:00,â€‡4.08MB/s]"}},"617ddd6ba82a401ca6ff54df9583ed86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abc0c2300f2649de84c120e86532f394","IPY_MODEL_3ded4f7155304204851673163352bd27","IPY_MODEL_8b1a9737521a4a7ba9162a953e6ecf10"],"layout":"IPY_MODEL_4ad07e7bd31f4396b677c763d9f2d10b"}},"62451753d71545c78625853cf9c2720f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a695637b0134716ac1fbc3fb1ea53d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db5337347ab462daee5753dadbcd006":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc677d10b5474f939a1fe50be47d2a00","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a79bc0889b884f25b91c6e3a621b9214","value":760}},"715c887f2fc749d8b202e882668d5650":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"771e7f532e984b83a05aa53c82584dc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78dcd6603a0b455b9ced95011fd21920":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81b4b2879b7546feba01edbfbf2c0fff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"896fd88532104163a369a4bcd605aa2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1caf2f3ea84c0480d324fb5a4af200":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1a9737521a4a7ba9162a953e6ecf10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_896fd88532104163a369a4bcd605aa2b","placeholder":"â€‹","style":"IPY_MODEL_f944e7e465ec4b389741cd3396fe7d05","value":"â€‡1.38M/1.38Mâ€‡[00:00&lt;00:00,â€‡9.26MB/s]"}},"8e6a815560214aafb203cbca4f2a9884":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e2eed49e43b43869e1932b1fa3c230c","IPY_MODEL_6db5337347ab462daee5753dadbcd006","IPY_MODEL_d3c4e0ecdf7b4da98372c22cf5166541"],"layout":"IPY_MODEL_81b4b2879b7546feba01edbfbf2c0fff"}},"9d0def64b25249238c1016622a3ab48a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a79bc0889b884f25b91c6e3a621b9214":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abc0c2300f2649de84c120e86532f394":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a1caf2f3ea84c0480d324fb5a4af200","placeholder":"â€‹","style":"IPY_MODEL_715c887f2fc749d8b202e882668d5650","value":"tokenizer.json:â€‡100%"}},"ad5211b78b2c4adb8aa5b373fd14cce8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b99ece4666294bcd88ea7ed876555d36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc3f4cdf0bae43cab86c43829fab3d03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3c4e0ecdf7b4da98372c22cf5166541":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_771e7f532e984b83a05aa53c82584dc6","placeholder":"â€‹","style":"IPY_MODEL_b99ece4666294bcd88ea7ed876555d36","value":"â€‡760/760â€‡[00:00&lt;00:00,â€‡45.8kB/s]"}},"e0cbb2f4ce3c475d9b05a808173a9b1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a695637b0134716ac1fbc3fb1ea53d9","placeholder":"â€‹","style":"IPY_MODEL_e36fd5315459498fb3016ab4208718bc","value":"spiece.model:â€‡100%"}},"e0d3b3eac2614142ae9b868bf92db50d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51d54350a22e49b5b0da16cdd49a78ab","IPY_MODEL_35eef1e75a59414b909e90a050e9ac3b","IPY_MODEL_527cda7172d943f992edc72796734825"],"layout":"IPY_MODEL_40e540f45f0d415fbb0547dfec04ab5d"}},"e36fd5315459498fb3016ab4208718bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1d8bcbc6a3e4b68b2e4e3ab848dacd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6cf0e55619b419b940e447764f6e31b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f944e7e465ec4b389741cd3396fe7d05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc677d10b5474f939a1fe50be47d2a00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}