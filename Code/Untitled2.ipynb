{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgahEPO1RfVW","outputId":"bb842566-1c6f-44cf-e89f-5edc5ae2fa52","executionInfo":{"status":"ok","timestamp":1736431294964,"user_tz":-330,"elapsed":1607364,"user":{"displayName":"ANBARASAN T 22CSR017","userId":"16535093453500537596"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Data Columns: Index(['Text', 'Label'], dtype='object')\n","Validation Accuracy: 0.5697991967871486\n","Classification Report:\n","                precision    recall  f1-score   support\n","\n","Mixed_feelings       0.25      0.19      0.22       694\n","      Negative       0.29      0.42      0.34       776\n","      Positive       0.75      0.73      0.74      3695\n"," unknown_state       0.40      0.38      0.39      1060\n","\n","      accuracy                           0.57      6225\n","     macro avg       0.42      0.43      0.42      6225\n","  weighted avg       0.58      0.57      0.57      6225\n","\n","Predictions saved to /content/drive/MyDrive/codalab/tam_prediction.csv\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","import re\n","import joblib\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import GridSearchCV\n","\n","# Preprocess the text data\n","def preprocess_text(text):\n","    # Lowercasing the text\n","    text = text.lower()\n","    # Remove non-alphanumeric characters (keeping spaces)\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    # Remove digits\n","    text = re.sub(r'\\d+', '', text)\n","    return text\n","\n","# File paths for train and test data\n","train_file_path = '/content/Tam-SA-train.csv'\n","test_file_path = '/content/Tam-SA-test-without-labels.csv'\n","\n","# Reading the data\n","train_data = pd.read_csv(train_file_path)\n","test_data = pd.read_csv(test_file_path)\n","\n","# Check the column names in the train dataset\n","print(\"Train Data Columns:\", train_data.columns)\n","\n","# Adjusting column name based on your dataset\n","# The 'Label' column contains the sentiment labels, so we'll use that\n","label_encoder = LabelEncoder()\n","train_data['labels_encoded'] = label_encoder.fit_transform(train_data['Label'])\n","\n","# Preprocess the text in both train and test datasets\n","train_data['Text'] = train_data['Text'].apply(preprocess_text)\n","test_data['Text'] = test_data['Text'].apply(preprocess_text)\n","\n","# TF-IDF Vectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=500)\n","X = tfidf_vectorizer.fit_transform(train_data['Text']).toarray()\n","y = train_data['labels_encoded']\n","\n","# Splitting the dataset into train and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Handling class imbalance using SMOTE (Synthetic Minority Oversampling Technique)\n","smote = SMOTE(random_state=42)\n","X_res, y_res = smote.fit_resample(X_train, y_train)\n","\n","# Hyperparameter tuning using GridSearchCV\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2]\n","}\n","grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1)\n","grid_search.fit(X_res, y_res)\n","\n","# Best model from grid search\n","clf_best = grid_search.best_estimator_\n","\n","# Train the model using the best hyperparameters\n","clf_best.fit(X_res, y_res)\n","\n","# Evaluate the model\n","y_pred = clf_best.predict(X_val)\n","accuracy = accuracy_score(y_val, y_pred)\n","print(f'Validation Accuracy: {accuracy}')\n","\n","# Classification report\n","report = classification_report(y_val, y_pred, target_names=label_encoder.classes_)\n","print('Classification Report:')\n","print(report)\n","\n","# Save the trained model, TF-IDF vectorizer, and label encoder\n","joblib.dump(clf_best, 'random_forest_model.pkl')\n","joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n","joblib.dump(label_encoder, 'label_encoder.pkl')\n","\n","# Function to test the model with new text input\n","def test_model(text, clf, tfidf_vectorizer, label_encoder):\n","    text_tfidf = tfidf_vectorizer.transform([preprocess_text(text)]).toarray()\n","    prediction = clf.predict(text_tfidf)\n","    predicted_label = label_encoder.inverse_transform(prediction)\n","    return predicted_label[0]\n","\n","# Apply the model to the test dataset\n","test_data['Predicted'] = test_data['Text'].apply(lambda text: test_model(text, clf_best, tfidf_vectorizer, label_encoder))\n","\n","# Save the predictions to a new CSV file\n","output_file_path = '/content/drive/MyDrive/codalab/tam_prediction.csv'\n","test_data.to_csv(output_file_path, index=False)\n","\n","print(f'Predictions saved to {output_file_path}')\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1c05UBmLOEHrsh4z6jwhQQhbG3o6cFcp_","authorship_tag":"ABX9TyN9ZLD6MSE48DS9SsG/pxbq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}